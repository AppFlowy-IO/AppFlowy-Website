---
title: AppFlowy Local AI is now FREE for everyone to use with Ollama integration
description: Use AppFlowy AI features powered by a local model installed through Ollama. You get the power of AppFlowy + AI while keeping your data private and secure.
author: AppFlowy
author_url: https://github.com/AppFlowy-IO
author_image_url: /images/blog/authors/appflowy.png
image: /images/blog/2025-04-03/appflowy_local_ai_ollama.png
thumb: /images/blog/2025-04-03/appflowy_local_ai_ollama.png
tags:
  - local_on-device_ai
  - ollama
  - deepseek
  - llama
  - security
categories:
  - Open source
  - Using AppFlowy
date: 2025-04-03
toc_depth: 3
pinned: 1
---

**AppFlowy Local AI is now FREE for everyone to use.**

We also integrated Ollama ðŸ¦™, which allows you to use AppFlowy AI features powered by LLMs directly on your local
machine.

<Video src="https://www.youtube.com/embed/IG_JTabjOOA?si=vmQx2SjpaKX-zriJ" alt="AppFlowy Local AI is now FREE for everyone to use" />


## What is Ollama

<Img src="/images/blog/2025-04-03/ollama_run_llm_locally.png" alt="The Benefits of Kanban in Project Management" />


[Ollama](https://ollama.com/) is a popular tool designed to run open source large language models (LLMs) locally on your
machine, ensuring data privacy and reducing latency compared to cloud-based solutions. It supports a variety of open
source models, including Llama 3.1, DeepSeek R1, Gemma 3, Phi4, and others, catering to tasks like text generation, code
generation, and summarization.

## Local (On-Device) AI vs Traditional AI Models

- On-device AI processes data locally, offering low latency, enhanced privacy, and offline functionality. However, itâ€™s
  limited by your device's hardware.

* Cloud AI, like OpenAI and Anthropic, requires a server connection. Every time you ask a question, your request is sent
  securely to a third-party server for processing.

## What is AppFlowy Local AI x Ollama

AppFlowy integrates with Ollama to bring local AI functionality, letting you use AppFlowy AI features powered by a local
model installed through Ollama. This way, you get the power of AppFlowy + AI while keeping your data private and secure.

## Why use AppFlowy Local AI?

* Maximum privacy and security â€“ Your data is not sent to AI service providers
* Stay in the flow â€“ Get powerful AI assistance without interruptions
* All-in-one experience â€“ Enjoy AppFlowy's rich features without switching tools

## What features does AppFlowy Local AI support?

ðŸ’¬ AI Chat (refer to [this guide](https://appflowy.com/guide/intro-to-appflowy-ai))
Please note that text-to-image is not yet available in AppFlowy Local AI.

ðŸ†• AI Writers in Document:

* Ask AI anything â€“ Get inspiration, create your first draft, and expand on a topic further
* Summarize â€“ Write a summary of your content
* Fix spelling & grammar
* Continue writing â€“ Expand on a topic further
* Improve writing â€“ Polish and improve the flow
* Explain a concept
* Make longer â€“ Hit the word minimum requirement
* Make shorter â€“ Meet the word maximum requirement

## ðŸ’¡ How do I get started:

AppFlowy Local AI is currently available on macOS (M1 or above), Windows (10 or above) and Linux.

Please update your desktop app to the latest and follow
this [guide](https://appflowy.com/guide/appflowy-local-ai-ollama) to get started!

Want to be the first to hear about new features? Follow us on [X](https://x.com/appflowy) , and join the conversations
in our community on [Reddit](https://www.reddit.com/r/AppFlowy/) or [Discord](https://discord.gg/9Q2xaN37tV) .

